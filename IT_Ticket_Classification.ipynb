{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513e33b3-622d-4e0b-891c-56777a24c974",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Automated Classification of IT Service Tickets Using OpenAI API\n",
    "\n",
    "---\n",
    "**Project Objective**: Leverage the OpenAI API to automatically classify IT service tickets into predefined categories, including:\n",
    "\n",
    "\n",
    "1. Hardware\n",
    "2.  Acces\n",
    "3. 3 Miscellaneo\n",
    "4. \n",
    "4 HR Supp\n",
    "5. \r\n",
    "5 Purc\n",
    "6. e\r\n",
    "6 Administrative r\n",
    "7. ts\r\n",
    "7 S\n",
    "8. age\r\n",
    "8 Internal   \n",
    "\n",
    "Post-classification, the results will be compared with pre-labeled categories to assess accuracy and effectiveness.Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a6c4a-c703-4fcb-b6d6-ae2d9e493b9c",
   "metadata": {},
   "source": [
    "## Installing Necessary Library and Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2162dd09-df78-4ede-91f1-8ea03a4e814b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: openai 1.55.3\n",
      "Uninstalling openai-1.55.3:\n",
      "  Successfully uninstalled openai-1.55.3\n",
      "Found existing installation: pydantic 1.10.9\n",
      "Uninstalling pydantic-1.10.9:\n",
      "  Successfully uninstalled pydantic-1.10.9\n",
      "Found existing installation: typing_extensions 4.11.0\n",
      "Uninstalling typing_extensions-4.11.0:\n",
      "  Successfully uninstalled typing_extensions-4.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\~ydantic'.\n",
      "You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "#pip uninstall -y openai pydantic typing_extensions\n",
    "#start cost $3.69\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2117ce0-f2ae-4284-bac5-3892d184ee77",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.55.3Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached openai-1.55.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pydantic==1.10.9\n",
      "  Using cached pydantic-1.10.9-cp311-cp311-win_amd64.whl.metadata (149 kB)\n",
      "Collecting typing_extensions==4.11\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai==1.55.3) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai==1.55.3) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai==1.55.3) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai==1.55.3) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai==1.55.3) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai==1.55.3) (4.65.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.55.3) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.55.3) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.55.3) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.55.3) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai==1.55.3) (0.4.6)\n",
      "Using cached openai-1.55.3-py3-none-any.whl (389 kB)\n",
      "Using cached pydantic-1.10.9-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: typing_extensions, pydantic, openai\n",
      "Successfully installed openai-1.55.3 pydantic-1.10.9 typing_extensions-4.11.0\n"
     ]
    }
   ],
   "source": [
    "pip install openai==1.55.3 pydantic==1.10.9 typing_extensions==4.11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e471b2-e14f-49e2-b00f-fbb5f213045c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\user\\anaconda3\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\user\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kaggle) (2.0.7)\n",
      "Requirement already satisfied: bleach in c:\\users\\user\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from bleach->kaggle) (24.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Installing Kaggle in this environment\n",
    "!pip install kaggle\n",
    "\n",
    "# To ignore warinings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f783c039-33c7-4f7b-ab9c-aa60ad527144",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#importing libraries and Dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939e9451-f5df-41bb-82cf-c17cb42ae5ef",
   "metadata": {},
   "source": [
    "**Authentication**\n",
    "---\n",
    "\n",
    "The dataset used in this project was gotten from Kaggle ([Dataset Link](https://www.kaggle.com/datasets/adisongoh/it-service-ticket-classification-dataset\")). \n",
    "\n",
    "To automate workflows and safeguard API keys in our project, we securely store credentials in an Excel file hosted on OneDrive. This approach allows for seamless integration and centralized management of sensitive information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45547be7-c941-4cdd-9aea-1629f76476f5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#importing OpenAI credentials and Kaggle API stored as excel file\n",
    "credentials = pd.read_excel(\"OneDrive/ALT School/kaggle_open.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11d1bc52-d478-4292-87c6-9f91be95e3de",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up Kaggle username and API key\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.environ[\"KAGGLE_USERNAME\"] = credentials[\"Username\"].iloc[0]\n",
    "os.environ[\"KAGGLE_KEY\"] = credentials[\"API Keys\"].iloc[0]\n",
    "api= KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e94505-c47d-455c-855d-ba5af86b914c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/adisongoh/it-service-ticket-classification-dataset\n",
      "Files in the dataset directory: [WindowsPath('OneDrive/ALT School/it-service-ticket-classification-dataset.zip')]\n"
     ]
    }
   ],
   "source": [
    "#Specifying the dataset to download from Kaggle\n",
    "dataset_name = \"adisongoh/it-service-ticket-classification-dataset\"\n",
    "#Setting the path where to save the downloaded data\n",
    "download_path = Path(\"OneDrive/ALT School/\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "download_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "api.dataset_download_files(dataset_name, path=download_path, unzip=False)\n",
    "\n",
    "# List the files in the downloaded dataset directory\n",
    "dataset_files = list(download_path.glob(\"*\"))\n",
    "print(\"Files in the dataset directory:\", dataset_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1130b35a-4fc3-47cc-91c3-2d4e338d4280",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all_tickets_processed_improved_v3.csv']\n",
      "                                            Document    Topic_group\n",
      "0  connection with icon icon dear please setup ic...       Hardware\n",
      "1  work experience user work experience user hi w...         Access\n",
      "2  requesting for meeting requesting meeting hi p...       Hardware\n",
      "3  reset passwords for external accounts re expir...         Access\n",
      "4  mail verification warning hi has got attached ...  Miscellaneous\n"
     ]
    }
   ],
   "source": [
    "#unzipping file that is downloaded\n",
    "import zipfile\n",
    "\n",
    "# Define the path to your ZIP file\n",
    "zip_path = \"OneDrive/ALT School/it-service-ticket-classification-dataset.zip\"\n",
    "\n",
    "# Open the ZIP file and list contents\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    print(z.namelist())  # List files inside the ZIP\n",
    "\n",
    "# Select the CSV file you want to load (assuming there's only one CSV)\n",
    "csv_filename = z.namelist()[0]  # Pick the first file\n",
    "\n",
    "# Read the CSV directly from ZIP\n",
    "df = pd.read_csv(zip_path, compression=\"zip\")\n",
    "print(df.head())  # Show first 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24e08d76-f8aa-4803-ada1-1fa2192b868c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connection with icon icon dear please setup ic...</td>\n",
       "      <td>Hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work experience user work experience user hi w...</td>\n",
       "      <td>Access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>requesting for meeting requesting meeting hi p...</td>\n",
       "      <td>Hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reset passwords for external accounts re expir...</td>\n",
       "      <td>Access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mail verification warning hi has got attached ...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       category\n",
       "0  connection with icon icon dear please setup ic...       Hardware\n",
       "1  work experience user work experience user hi w...         Access\n",
       "2  requesting for meeting requesting meeting hi p...       Hardware\n",
       "3  reset passwords for external accounts re expir...         Access\n",
       "4  mail verification warning hi has got attached ...  Miscellaneous"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffecb796-0a2d-4ef4-9031-df4f2296429f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function rename in module pandas.core.frame:\n",
      "\n",
      "rename(self, mapper: 'Renamer | None' = None, *, index: 'Renamer | None' = None, columns: 'Renamer | None' = None, axis: 'Axis | None' = None, copy: 'bool | None' = None, inplace: 'bool' = False, level: 'Level | None' = None, errors: 'IgnoreRaise' = 'ignore') -> 'DataFrame | None'\n",
      "    Rename columns or index labels.\n",
      "    \n",
      "    Function / dict values must be unique (1-to-1). Labels not contained in\n",
      "    a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      "    error.\n",
      "    \n",
      "    See the :ref:`user guide <basics.rename>` for more.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    mapper : dict-like or function\n",
      "        Dict-like or function transformations to apply to\n",
      "        that axis' values. Use either ``mapper`` and ``axis`` to\n",
      "        specify the axis to target with ``mapper``, or ``index`` and\n",
      "        ``columns``.\n",
      "    index : dict-like or function\n",
      "        Alternative to specifying axis (``mapper, axis=0``\n",
      "        is equivalent to ``index=mapper``).\n",
      "    columns : dict-like or function\n",
      "        Alternative to specifying axis (``mapper, axis=1``\n",
      "        is equivalent to ``columns=mapper``).\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Axis to target with ``mapper``. Can be either the axis name\n",
      "        ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      "    copy : bool, default True\n",
      "        Also copy underlying data.\n",
      "    inplace : bool, default False\n",
      "        Whether to modify the DataFrame rather than creating a new one.\n",
      "        If True then value of copy is ignored.\n",
      "    level : int or level name, default None\n",
      "        In case of a MultiIndex, only rename labels in the specified\n",
      "        level.\n",
      "    errors : {'ignore', 'raise'}, default 'ignore'\n",
      "        If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n",
      "        or `columns` contains labels that are not present in the Index\n",
      "        being transformed.\n",
      "        If 'ignore', existing keys will be renamed and extra keys will be\n",
      "        ignored.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or None\n",
      "        DataFrame with the renamed axis labels or None if ``inplace=True``.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    KeyError\n",
      "        If any of the labels is not found in the selected axis and\n",
      "        \"errors='raise'\".\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.rename_axis : Set the name of the axis.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    ``DataFrame.rename`` supports two calling conventions\n",
      "    \n",
      "    * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      "    * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      "    \n",
      "    We *highly* recommend using keyword arguments to clarify your\n",
      "    intent.\n",
      "    \n",
      "    Rename columns using a mapping:\n",
      "    \n",
      "    >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "    >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
      "       a  c\n",
      "    0  1  4\n",
      "    1  2  5\n",
      "    2  3  6\n",
      "    \n",
      "    Rename index using a mapping:\n",
      "    \n",
      "    >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
      "       A  B\n",
      "    x  1  4\n",
      "    y  2  5\n",
      "    z  3  6\n",
      "    \n",
      "    Cast index labels to a different type:\n",
      "    \n",
      "    >>> df.index\n",
      "    RangeIndex(start=0, stop=3, step=1)\n",
      "    >>> df.rename(index=str).index\n",
      "    Index(['0', '1', '2'], dtype='object')\n",
      "    \n",
      "    >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n",
      "    Traceback (most recent call last):\n",
      "    KeyError: ['C'] not found in axis\n",
      "    \n",
      "    Using axis-style parameters:\n",
      "    \n",
      "    >>> df.rename(str.lower, axis='columns')\n",
      "       a  b\n",
      "    0  1  4\n",
      "    1  2  5\n",
      "    2  3  6\n",
      "    \n",
      "    >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      "       A  B\n",
      "    0  1  4\n",
      "    2  2  5\n",
      "    4  3  6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I forgot how to use the rename function and the help function serve as usefull reminder\n",
    "help(pd.DataFrame.rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea8cca86-4aa2-4961-a514-f77f6ee36c3f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#renaming the columns in the dataframe\n",
    "df = df.rename(columns={'Document':'text','Topic_group':'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc1ab6f9-d336-49a4-b9ad-80cccfac0d98",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 unique category in this column \n",
      "They are listed below \n",
      "\n",
      "1 Hardware\n",
      "2 Access\n",
      "3 Miscellaneous\n",
      "4 HR Support\n",
      "5 Purchase\n",
      "6 Administrative rights\n",
      "7 Storage\n",
      "8 Internal Project\n"
     ]
    }
   ],
   "source": [
    "# Checking the Category Column\n",
    "print('There are {} unique category in this column \\nThey are listed below \\n'.format(len(df['category'].unique())))\n",
    "n=0\n",
    "for cat in df['category'].unique():\n",
    "    n+=1\n",
    "    print(n,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16869728-8792-4728-96a2-999823cb6768",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#importing openai library and loading the API key\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=credentials[\"API Keys\"].iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc1ca50c-61e9-4b7a-ac30-3ca8b35ff6e0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#creating a function based code snippet in the open AI playground to classify the text\n",
    "def classify_text(text, categories):\n",
    "    \"\"\"Function to classify text into predefined categories using OpenAI API.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a text classification model. Categorize the following text into one of these categories: {\", \".join(categories)}.\n",
    "    \n",
    "    Text: \"{text}\"\n",
    "    \n",
    "    Respond only with the category name.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"developer\", \"content\": prompt}],\n",
    "        temperature=0  # Ensures consistency\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ca2545d-f8cb-4a80-820d-6a71ed1cd6f3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hardware', 'Access', 'Miscellaneous', 'HR Support', 'Purchase', 'Administrative rights', 'Storage', 'Internal Project']\n"
     ]
    }
   ],
   "source": [
    "# Define categories\n",
    "categories = ['Hardware', 'Access', 'Miscellaneous', 'HR Support', 'Purchase', 'Administrative rights', 'Storage', 'Internal Project']\n",
    "#printing categories variable for verification\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1b8ebec-b3e1-4700-8187-34a062520a74",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# using only 100 rows of the dataframe to save API cost\n",
    "df_sample = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "306510ff-038e-4e3d-bbed-20e64f93513d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# using lambda function to run our defined function \n",
    "df_sample['pred'] = df_sample['text'].apply(lambda x: classify_text(x, categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a7a00a2-9a51-4bc9-b7d0-abe30d83ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping the category values to numbers\n",
    "df_sample['pred_num'] = df_sample['pred'].map({ 'Hardware':0, 'Access':1, 'Miscellaneous':2, 'HR Support':3,\n",
    "                                                             'Purchase':4, 'Administrative rights':5, 'Storage':5, 'Internal Project':6})\n",
    "df_sample['category_num'] = df_sample['category'].map({ 'Hardware':0, 'Access':1, 'Miscellaneous':2, 'HR Support':3,\n",
    "                                                             'Purchase':4, 'Administrative rights':5, 'Storage':5, 'Internal Project':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "773c0d4e-9e5f-4aaf-be6d-fd439ca157ea",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_num</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38704</th>\n",
       "      <td>not connecting a wrong gateway connecting wron...</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Access</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46002</th>\n",
       "      <td>not working after click report redirecting aga...</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Access</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17268</th>\n",
       "      <td>new starter nae bucharest thursday march pm he...</td>\n",
       "      <td>HR Support</td>\n",
       "      <td>HR Support</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>activation on employee locator activation dear...</td>\n",
       "      <td>Access</td>\n",
       "      <td>Access</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45018</th>\n",
       "      <td>mail is not working sent thursday working hell...</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>Access</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    category  \\\n",
       "38704  not connecting a wrong gateway connecting wron...    Hardware   \n",
       "46002  not working after click report redirecting aga...    Hardware   \n",
       "17268  new starter nae bucharest thursday march pm he...  HR Support   \n",
       "8125   activation on employee locator activation dear...      Access   \n",
       "45018  mail is not working sent thursday working hell...    Hardware   \n",
       "\n",
       "             pred  pred_num  category_num  \n",
       "38704      Access         1             0  \n",
       "46002      Access         1             0  \n",
       "17268  HR Support         3             3  \n",
       "8125       Access         1             1  \n",
       "45018      Access         1             0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing top 5 rows\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64ff3eba-1cd3-493f-911b-4f1a4c153ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53\n"
     ]
    }
   ],
   "source": [
    "#checking the accuracy of the openAI to the predefined category\n",
    "print(accuracy_score(df_sample['pred_num'].values, df_sample['category_num'].values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf0a80-fe0e-41e2-94b9-418bff8dad89",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "---\n",
    "The model achieved an accuracy of 53% when compared to the predefined categories. However, this figure should be interpreted cautiously, as the reliability of the predefined categories themselves is uncertain. This uncertainty underscores the challenges in evaluating model performance without a definitive ground truth.\n",
    "\n",
    "In summary, while the project showcased the advantages of leveraging large language models for text classification without extensive training data, it also illuminated the critical need for dependable evaluation metrics and the potential benefits of domain-specific fine-tuning.\n",
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38453212-a4f7-47b9-8178-c7b1c9ce5097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "2690914e-8cf0-4f18-93f8-142cf4a8e3a7",
    "default_lakehouse_name": "textdata",
    "default_lakehouse_workspace_id": "98db674c-394d-4bb3-ab08-e2453846c3b2"
   }
  },
  "kernel_info": {
   "jupyter_kernel_name": "python3.10",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
